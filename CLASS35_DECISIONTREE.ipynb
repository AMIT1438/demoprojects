{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70b6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e865277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3bd417",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ed2fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris=load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3509501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.DataFrame(data=iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29130a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=iris.data\n",
    "y=iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3380d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.22,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc43f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bcbdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.94      0.93      0.93        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "dtc.score(x_train,y_train)\n",
    "predsvc=dtc.predict(x_test)\n",
    "print(accuracy_score(y_test,predsvc))\n",
    "print(confusion_matrix(y_test,predsvc))\n",
    "print(classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad1570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1f90b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9393939393939394\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.94        33\n",
      "   macro avg       0.94      0.93      0.93        33\n",
      "weighted avg       0.95      0.94      0.94        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='rbf')\n",
    "svc.fit(x_train,y_train)\n",
    "svc.score(x_train,y_train)\n",
    "predsvc=svc.predict(x_test)\n",
    "print(accuracy_score(y_test,predsvc))\n",
    "print(confusion_matrix(y_test,predsvc))\n",
    "print(classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "921f8c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc=SVC(kernel='poly')\n",
    "svc.fit(x_train,y_train)\n",
    "svc.score(x_train,y_train)\n",
    "predsvc=svc.predict(x_test)\n",
    "print(accuracy_score(y_test,predsvc))\n",
    "print(confusion_matrix(y_test,predsvc))\n",
    "print(classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f821cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmkernel(ker):\n",
    "    svc=SVC(kernel=ker)\n",
    "    svc.fit(x_train,y_train)\n",
    "    svc.score(x_train,y_train)\n",
    "    predsvc=svc.predict(x_test)\n",
    "    print(accuracy_score(y_test,predsvc))\n",
    "    print(confusion_matrix(y_test,predsvc))\n",
    "    print(classification_report(y_test,predsvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31ef0218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2727272727272727\n",
      "[[ 0  0 14]\n",
      " [ 0  0 10]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00        10\n",
      "           2       0.27      1.00      0.43         9\n",
      "\n",
      "    accuracy                           0.27        33\n",
      "   macro avg       0.09      0.33      0.14        33\n",
      "weighted avg       0.07      0.27      0.12        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svmkernel('sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18130f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n",
      "[[38  6]\n",
      " [ 0 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93        44\n",
      "           1       0.93      1.00      0.96        82\n",
      "\n",
      "    accuracy                           0.95       126\n",
      "   macro avg       0.97      0.93      0.95       126\n",
      "weighted avg       0.96      0.95      0.95       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svmkernel('poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61c9707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841269841269841\n",
      "[[43  1]\n",
      " [ 1 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        44\n",
      "           1       0.99      0.99      0.99        82\n",
      "\n",
      "    accuracy                           0.98       126\n",
      "   macro avg       0.98      0.98      0.98       126\n",
      "weighted avg       0.98      0.98      0.98       126\n",
      "\n",
      "\n",
      "\n",
      "0.9523809523809523\n",
      "[[38  6]\n",
      " [ 0 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93        44\n",
      "           1       0.93      1.00      0.96        82\n",
      "\n",
      "    accuracy                           0.95       126\n",
      "   macro avg       0.97      0.93      0.95       126\n",
      "weighted avg       0.96      0.95      0.95       126\n",
      "\n",
      "\n",
      "\n",
      "0.9523809523809523\n",
      "[[38  6]\n",
      " [ 0 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93        44\n",
      "           1       0.93      1.00      0.96        82\n",
      "\n",
      "    accuracy                           0.95       126\n",
      "   macro avg       0.97      0.93      0.95       126\n",
      "weighted avg       0.96      0.95      0.95       126\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ken=['linear','poly','rbf']\n",
    "for i in ken:\n",
    "    svmkernel(i)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1589711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(predsvc)\n",
    "df1.to_csv('svc_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86f84f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[14  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "knn.score(x_train,y_train)\n",
    "predknn=knn.predict(x_test)\n",
    "print(accuracy_score(y_test,predknn))\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(classification_report(y_test,predknn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "705a4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbac75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_breast_cancer()\n",
    "cancer_data=pd.DataFrame(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca6467ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          9   ...      20     21      22      23       24       25      26  \\\n",
       "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         27      28       29  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8076708f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "564  0\n",
       "565  0\n",
       "566  0\n",
       "567  0\n",
       "568  1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_target=pd.DataFrame(data.target)\n",
    "cancer_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac094971",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cancer_data\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d842ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1       2       3        4        5        6        7       8   \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "          9   ...      20     21      22      23       24       25      26  \\\n",
       "0    0.07871  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
       "1    0.05667  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
       "2    0.05999  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
       "3    0.09744  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
       "4    0.05883  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
       "564  0.05623  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
       "565  0.05533  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
       "566  0.05648  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
       "567  0.07016  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
       "568  0.05884  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
       "\n",
       "         27      28       29  \n",
       "0    0.2654  0.4601  0.11890  \n",
       "1    0.1860  0.2750  0.08902  \n",
       "2    0.2430  0.3613  0.08758  \n",
       "3    0.2575  0.6638  0.17300  \n",
       "4    0.1625  0.2364  0.07678  \n",
       "..      ...     ...      ...  \n",
       "564  0.2216  0.2060  0.07115  \n",
       "565  0.1628  0.2572  0.06637  \n",
       "566  0.1418  0.2218  0.07820  \n",
       "567  0.2650  0.4087  0.12400  \n",
       "568  0.0000  0.2871  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5c4135a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "995347ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.reshape(-1,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdad0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.22,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21e26d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg=LogisticRegression()\n",
    "lg.fit(x_train,y_train)\n",
    "\n",
    "pred=lg.predict(x_test)\n",
    "pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20ef0530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761904761904762\n",
      "[[42  2]\n",
      " [ 1 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        44\n",
      "           1       0.98      0.99      0.98        82\n",
      "\n",
      "    accuracy                           0.98       126\n",
      "   macro avg       0.98      0.97      0.97       126\n",
      "weighted avg       0.98      0.98      0.98       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0717b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=lg.predict_proba(x_test)[:,1]    #all rows of x_test and predict 1 as value\n",
    "\n",
    "y_pred_prob\n",
    "\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd91e5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.02272727, 0.02272727,\n",
       "       0.06818182, 0.06818182, 1.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48b0b5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01219512, 0.75609756, 0.75609756, 0.98780488,\n",
       "       0.98780488, 1.        , 1.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc9f226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99996399e+00, 9.99963990e-01, 9.60746933e-01, 9.60517607e-01,\n",
       "       5.99800803e-01, 3.18000277e-01, 1.59913488e-01, 4.56873915e-22])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f921fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr,label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a56ece95",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score=roc_auc_score(y_test,lg.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da44fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711751662971175"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f890beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [126, 33]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14360/4180420451.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredsvc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredsvc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [126, 33]"
     ]
    }
   ],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "dtc.score(x_train,y_train)\n",
    "p=dtc.predict(x_test)\n",
    "ac=accuracy_score(y_test,p)\n",
    "round(ac,3)\n",
    "print(ac)\n",
    "print(confusion_matrix(y_test,predsvc))\n",
    "print(classification_report(y_test,predsvc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=dtc.predict_proba(x_test)[:,1]    #all rows of x_test and predict 1 as value\n",
    "\n",
    "y_pred_prob\n",
    "\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr,label='Decision Tree Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score=roc_auc_score(y_test,lg.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97431ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ffd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
